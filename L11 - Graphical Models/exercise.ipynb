{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Graphical Models\n",
    "\n",
    "*Description: A Markov Random Field (RMF) is an undirected graph model of joint probability distribution that uses undirected edges to represent soft constraints among nodes in the graph. *\n",
    "\n",
    "The notebook shows how a RMF can be used for image restoration. Specifically, we follow http://homepages.inf.ed.ac.uk/rbf/CVonline/LOCAL_COPIES/AV0809/ORCHARD/, in which a MATLAB implementation of an Iterated Conditional Modes (ICM) algorithm is presented. Here we implement the ICM algorithm using Python and use it for a simple example.\n",
    "\n",
    "Algorithm Illustration by Code, supporting course material for Machine Learning, Zheng-Hua Tan, Aalborg University"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from skimage import data, color\n",
    "import matplotlib.pyplot as plt\n",
    "import numba"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Load an image \n",
    "\n",
    "First let's import an image from the skimage.data package, convert it to greyscale and show it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "image_rgb = data.rocket()\n",
    "# We convert to greyscale, by taking a average of the 3 (red (R), green (G) and blue (B)) color channels.\n",
    "image = np.round(np.mean(image_rgb, axis=2, dtype=np.int16))\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.imshow(image, cmap='gray')\n",
    "#plt.imshow(image_rgb)\n",
    "plt.gca().set_xticks([])\n",
    "plt.gca().set_yticks([])\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Generate Gaussian noise\n",
    "\n",
    "As we aim to use a RMF for image restoration, let's corrupt the image with noise first (in order to denoise it later on). We generate an additive noise value for each pixel in the image. The noise is generated according to a zero-mean Gaussian distribution and rounded to integers (as the pixel values are int16)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "var = 100\n",
    "\n",
    "noise = np.asarray(np.round(np.random.normal(loc=0,scale=np.sqrt(var),\n",
    "                                             size = image.shape)), dtype = np.int16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Add the noise to the image \n",
    "\n",
    "Then we add to the noise to the original image and limit the values in the range [0, 255]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "image_noisy = (image + noise)\n",
    "\n",
    "for i in range(image.shape[0]):\n",
    "    for j in range(image.shape[1]):\n",
    "        if image_noisy[i, j] > 255:\n",
    "            image_noisy[i, j] = 255\n",
    "        elif image_noisy[i, j] < 0:\n",
    "            image_noisy[i, j] = 0\n",
    "            \n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.imshow(image_noisy, cmap='gray')\n",
    "#plt.imshow(noise, cmap='gray')\n",
    "plt.gca().set_xticks([])\n",
    "plt.gca().set_yticks([])\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Implement the Iterated Conditional Modes algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Note that we use the decorator @numba.jit. This is a compiler that speeds up computation\n",
    "# This is very useful for nested loops that result in long computation time\n",
    "\n",
    "@numba.jit\n",
    "def func(_im_noise, _var, _iterations, _w_diff, _max_diff):\n",
    "    # The ICM algorithm takes the input image and produce a processed image.\n",
    "    # The processed image then acts as the input image for the following iteration.\n",
    "    # This is why we create an array with the image inside twice and then we can alternate which one to update.\n",
    "    image_buffer = np.array((np.copy(_im_noise), np.copy(_im_noise)))\n",
    "    \n",
    "    # This value is guaranteed to be larger than any potential of any configuration of pixel values.\n",
    "    V_max = _im_noise.shape[0] * _im_noise.shape[1] * (256**2) / (2 * _var) + 4 * _w_diff * _max_diff\n",
    "    \n",
    "    for n in range(_iterations):\n",
    "        \n",
    "        # These variables are for keeping track of indexing in the buffer image. \n",
    "        s = n % 2\n",
    "        d = (n + 1) % 2\n",
    "\n",
    "        # Now, we loop over all pixel values.\n",
    "        for i in range(_im_noise.shape[0]):\n",
    "            for j in range(_im_noise.shape[1]):\n",
    "\n",
    "                V_local = V_max\n",
    "                min_val = -1\n",
    "                \n",
    "                # The idea is to find the value for each pixel that minimizes the potential\n",
    "                for k in range(256):\n",
    "                    \n",
    "                    # Here we compute the component of the clique potential, if the (i,j)th pixel\n",
    "                    # is changed to k. See V_n in the provided link.\n",
    "                    V_data = (k - _im_noise[i, j])**2 / (2 * _var)\n",
    "                    \n",
    "                    V_diff = 0\n",
    "                    \n",
    "                    # Here we compute the component of the clique potential due to the difference\n",
    "                    # between neighbouring pixel values. See V_{mn} in the provided link.\n",
    "                    # The conditional statements are to combat edge effects\n",
    "                    if i > 0:\n",
    "                        V_diff += min(((k - image_buffer[s, i - 1, j])**2, _max_diff))\n",
    "                    if i < _im_noise.shape[0] - 1:\n",
    "                        V_diff += min(((k - image_buffer[s, i + 1, j])**2, _max_diff))\n",
    "                    if j > 0:\n",
    "                        V_diff += min(((k - image_buffer[s, i, j - 1])**2, _max_diff))\n",
    "                    if j < _im_noise.shape[1] - 1:\n",
    "                        V_diff += min(((k - image_buffer[s, i, j + 1])**2, _max_diff))\n",
    "                    \n",
    "                    # Compute the combined potential\n",
    "                    V_current = V_data + _w_diff * V_diff\n",
    "                    \n",
    "                    # We only update the values if new current potential is lower then the previous.\n",
    "                    # Remember we are minimizing.\n",
    "                    if V_current < V_local:\n",
    "                        min_val = k\n",
    "                        V_local = V_current\n",
    "                \n",
    "                # The buffer image is updated with the value that minimizes that potential.\n",
    "                image_buffer[d, i, j] = min_val\n",
    "    \n",
    "    return image_buffer[d]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Specify the hyper-parameters \n",
    "\n",
    "In order to run the algorithm, a few parameters need to be specified.\n",
    "- the variance in the clique potential, here let's use to variance that actually corrupted the image as an ideal case.\n",
    "- the number of iterations that the algorithms iterates over the image.\n",
    "- the weighting attached to the potential due to the difference between two neighbouring pixel values. ($\\gamma$ in the provided link).\n",
    "- the maximum contribtuion to the potential of the difference between two neighbouring pixel values ($\\beta$ in the provided link).\n",
    "\n",
    "Let's set these parameters and run the algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "iterations = 100\n",
    "w_diff = 0.015\n",
    "max_diff = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Run the algorithm\n",
    "\n",
    "The use of the numba.jit decorator will (maybe) raise an error. It is not ideal to ignore such errors, but we still achieve the desired speed up."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "image_recon = func(image_noisy, var, iterations, w_diff, max_diff)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Result \n",
    "\n",
    "Let's - by visual inspection - see how the algorithm performed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(30, 10))\n",
    "\n",
    "plt.subplot(131)\n",
    "\n",
    "plt.title('Original')\n",
    "plt.imshow(image, cmap='gray')\n",
    "plt.gca().set_xticks([])\n",
    "plt.gca().set_yticks([])\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.subplot(132)\n",
    "\n",
    "plt.title('Noisy')\n",
    "plt.imshow(image_noisy, cmap='gray')\n",
    "plt.gca().set_xticks([])\n",
    "plt.gca().set_yticks([])\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.subplot(133)\n",
    "\n",
    "plt.title('Reconstruction')\n",
    "plt.imshow(image_recon, cmap='gray')\n",
    "plt.gca().set_xticks([])\n",
    "plt.gca().set_yticks([])\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Discussion\n",
    "\n",
    "We see that the algorithm has smoothed the noise. Speficially surfaces of slowly-varying intensity, e.g., the sides of the boxes are well-restored. However, areas with rapidly-varying intensities, e.g., motorcycle parts and text, are not are well-reconsored. Try to change the paramters used throughout this notebook, i.e., noise variance, iterations, $\\gamma$ and $\\beta$ to see if better results can be achieved."
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
