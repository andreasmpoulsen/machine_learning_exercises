{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pItPKDzDAAfx"
      },
      "source": [
        "Machine Learning Mini-project:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8eG1_lTxCDLh"
      },
      "source": [
        "Importing libraries and unpickling dataset:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZO_ikIrw-hhr"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from numpy import linalg as LA\n",
        "import pandas as pd\n",
        "import scipy.io as sp\n",
        "from scipy.stats import multivariate_normal as norm\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
        "from sklearn.neighbors import KNeighborsClassifier as KNC\n",
        "from sklearn import svm\n",
        "from sklearn.tree import DecisionTreeClassifier as DTC\n",
        "\n",
        "\n",
        "\n",
        "def unpickle(file):\n",
        "    import pickle\n",
        "    with open(file, 'rb') as fo:\n",
        "        dict = pickle.load(fo, encoding='bytes')\n",
        "    return dict\n",
        "\n",
        "data_batch_1 = unpickle('cifar-10-batches-py/data_batch_1')\n",
        "data_batch_2 = unpickle('cifar-10-batches-py/data_batch_2')\n",
        "data_batch_3 = unpickle('cifar-10-batches-py/data_batch_3')\n",
        "data_batch_4 = unpickle('cifar-10-batches-py/data_batch_4')\n",
        "data_batch_5 = unpickle('cifar-10-batches-py/data_batch_5')\n",
        "test_batch = unpickle('cifar-10-batches-py/test_batch')\n",
        "batches = unpickle('cifar-10-batches-py/batches.meta')\n",
        "\n",
        "train_labels = np.concatenate((data_batch_1[b'labels'], data_batch_2[b'labels'],\n",
        "                              data_batch_3[b'labels'], data_batch_4[b'labels'], data_batch_5[b'labels']))\n",
        "train_data = np.concatenate((data_batch_1[b'data'], data_batch_2[b'data'],\n",
        "                            data_batch_3[b'data'], data_batch_4[b'data'], data_batch_5[b'data']))\n",
        "\n",
        "test_labels = np.array(test_batch[b'labels'])\n",
        "test_data = test_batch[b'data']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lCFgTG68CH8k"
      },
      "source": [
        "Calculating a 90% PoV and fitting PCA:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BL5h48H5CAdj",
        "outputId": "4c80d5b1-1d97-4eeb-845d-a0c99980454c"
      },
      "outputs": [],
      "source": [
        "cov = np.cov(train_data.T)\n",
        "eigvals = LA.eigvals(cov)\n",
        "\n",
        "eigvals[::-1].sort()\n",
        "eig_D = np.sum(eigvals)\n",
        "for i in range(len(eigvals)):\n",
        "    if np.sum(eigvals[:i+1])/eig_D > 0.9:\n",
        "        eig_M = i+1\n",
        "        break\n",
        "print(eig_M)\n",
        "pca = PCA(n_components=eig_M)\n",
        "pca.fit(train_data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XCUNt56oCOcz"
      },
      "source": [
        "Fitting and predicting with LDA:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ibXjOFJsCSkP",
        "outputId": "eaef95a7-97b8-424c-f38c-ad47f1459684"
      },
      "outputs": [],
      "source": [
        "new_train_data = pca.transform(train_data)\n",
        "clf_lda = LDA()\n",
        "clf_lda.fit(new_train_data, train_labels)\n",
        "\n",
        "new_test_data = pca.transform(test_data)\n",
        "lda_predictions = clf_lda.predict(new_test_data)\n",
        "print(clf_lda.score(new_test_data, test_labels))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZwgnGMO4CVn7"
      },
      "source": [
        "Fitting and predicting with Linear SVM:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dV64Bfo6CY7I"
      },
      "outputs": [],
      "source": [
        "clf_svm = svm.SVC(kernel='linear')\n",
        "clf_svm.fit(new_train_data, train_labels)\n",
        "\n",
        "svm_predictions = clf_svm.predict(new_test_data)\n",
        "\n",
        "print(clf_svm.score(new_test_data, test_labels))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CYwKl4hU7dZL"
      },
      "source": [
        "Convolutional Neural network with TensorFlow:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6Q2_8uBS7dZM"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import datasets, layers, models\n",
        "import matplotlib.pyplot as plt\n",
        "print(\"TensorFlow version:\", tf.__version__)\n",
        "\n",
        "(train_images, train_labels), (test_images, test_labels) = datasets.cifar10.load_data()\n",
        "\n",
        "# Normalize pixel values to be between 0 and 1\n",
        "train_images, test_images = train_images / 255.0, test_images / 255.0\n",
        "\n",
        "model = models.Sequential()\n",
        "model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3)))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(layers.Flatten())\n",
        "model.add(layers.Dense(64, activation='relu'))\n",
        "model.add(layers.Dense(10))\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t9O7ABudTP9d"
      },
      "outputs": [],
      "source": [
        "model.compile(optimizer='adam',\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(train_images, train_labels, epochs=6, \n",
        "                    validation_data=(test_images, test_labels))\n",
        "\n",
        "plt.plot(history.history['accuracy'], label='accuracy')\n",
        "plt.plot(history.history['val_accuracy'], label = 'val_accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.ylim([0.5, 1])\n",
        "plt.legend(loc='lower right')\n",
        "\n",
        "test_loss, test_acc = model.evaluate(test_images,  test_labels, verbose=2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QEaAcs8nN6OH"
      },
      "source": [
        "Fitting and predicting with K-nearest neighbor:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IRbUPK9-LSGw"
      },
      "outputs": [],
      "source": [
        "# error_rate = []\n",
        "# len_for = len(new_train_data)\n",
        "# for i in range(1, len_for):\n",
        "#   neigh = KNC(n_neighbors=i)\n",
        "#   #print(\"Making cluster(s): {0} of {1}\".format(i, int(len_for)))\n",
        "#   neigh.fit(new_train_data, train_labels)\n",
        "#   pred_i = neigh.predict(new_test_data)\n",
        "#   error_rate.append(np.mean(pred_i != test_labels))\n",
        "\n",
        "# k_clusters = error_rate.index(min(error_rate))\n",
        "# min_error = min(error_rate)\n",
        "# print(\"Minimum error:-\",min_error,\"at K =\",k_clusters)\n",
        "\n",
        "neigh2 = KNC(n_neighbors=10)\n",
        "neigh2.fit(new_train_data, train_labels)\n",
        "knn_predict = neigh2.predict(new_test_data)\n",
        "\n",
        "print(neigh2.score(new_test_data, test_labels))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TMSlKX4sOb7E"
      },
      "source": [
        "Decision Tree:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "miRwvT1aSs9T",
        "outputId": "67f6c037-c045-4f19-f6ea-648e28d961c7"
      },
      "outputs": [],
      "source": [
        "import graphviz\n",
        "from sklearn import tree\n",
        "#from sklearn.tree import plot_tree\n",
        "#import matplotlib.pyplot as plt\n",
        "\n",
        "predictions =[]\n",
        "\n",
        "for i in range(1, len(new_train_data)):\n",
        "  clf_dtc = DTC(max_depth=i, splitter=\"best\")\n",
        "  print(\"Fitting: {0}\".format(i))\n",
        "  clf_dtc.fit(new_train_data, train_labels)\n",
        "  #dot_data = tree.export_graphviz(clf_dtc, out_file = None)\n",
        "  #graph = graphviz.Source(dot_data)\n",
        "  #graph.render(\"CLF_DTC\")\n",
        "  dtc_predictions = clf_dtc.predict(new_test_data)\n",
        "  predictions.append(dtc_predictions)\n",
        "\n",
        "best_prediction = max(predictions)\n",
        "max_d_index = predictions.index(best_prediction)\n",
        "print(max_d_index)\n",
        "print(clf_dtc.score(new_test_data, test_labels))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "ML_MiniProject.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
